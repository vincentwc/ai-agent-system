import streamlit as st
import time
from rag import RagService
import config_data as config
from langchain_community.embeddings import DashScopeEmbeddings

# æ ‡é¢˜
st.title("æ™ºèƒ½å®¢æœ")
st.divider()  # åˆ†éš”çº¿


if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ ï¼Ÿ"}
    ]

if "rag" not in st.session_state:
    st.session_state["rag"] = RagService(
        embedding=DashScopeEmbeddings(model=config.embedding_model)
    )

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state["messages"]:
    role = message["role"]
    avatar = "ğŸ§‘â€ğŸ’»" if role == "user" else "ğŸ¤–"
    st.chat_message(role, avatar=avatar).write(message["content"])

# ç”¨æˆ·è¾“å…¥æ¡†
# user_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š")
prompt = st.chat_input()

if prompt:
    # åœ¨é¡µé¢è¾“å‡ºç”¨æˆ·çš„æé—®
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").write(prompt)

    st.session_state["messages"].append({"role": "user", "content": prompt})

    ai_res_list = []
    with st.spinner("AIæ€è€ƒä¸­..."):
        res_stream = st.session_state["rag"].chain.stream(
            {"input": prompt}, config.session_config
        )
        
        def capture(generator,cache_list):
          for chunk in generator:
            cache_list.append(chunk)
            yield chunk
        
        
        # åœ¨é¡µé¢è¾“å‡ºå®¢æœçš„å›ç­”
        st.chat_message("assistant", avatar="ğŸ¤–").write(capture(res_stream,ai_res_list))
        # ç¼“å­˜å®¢æœçš„å›ç­”
        st.session_state["messages"].append({"role": "assistant", "content": "".join(ai_res_list)})
